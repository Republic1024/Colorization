{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-24T17:47:37.031123900Z",
     "start_time": "2024-09-24T17:47:37.018090800Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 160, 160])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"卷积块：Conv2d -> BatchNorm2d -> ReLU\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, stride=2):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels, out_channels,\n",
    "            kernel_size=3, stride=stride,\n",
    "            padding=1\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class UpConvBlock(nn.Module):\n",
    "    \"\"\"上采样块：ConvTranspose2d -> BatchNorm2d -> ReLU\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, stride=2):\n",
    "        super(UpConvBlock, self).__init__()\n",
    "        self.upconv = nn.ConvTranspose2d(\n",
    "            in_channels, out_channels,\n",
    "            kernel_size=3, stride=stride,\n",
    "            padding=1, output_padding=1\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self, x):\n",
    "        x = self.upconv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class SeparableConv2d(nn.Module):\n",
    "    \"\"\"深度可分离卷积：Depthwise Conv2d + Pointwise Conv2d\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(SeparableConv2d, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(\n",
    "            in_channels, in_channels,\n",
    "            kernel_size=3, padding=1,\n",
    "            groups=in_channels, bias=False\n",
    "        )\n",
    "        self.pointwise = nn.Conv2d(\n",
    "            in_channels, out_channels,\n",
    "            kernel_size=1, bias=False\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "\n",
    "class ColorizationUNet(nn.Module):\n",
    "    \"\"\"用于灰度图像上色的U-Net模型\"\"\"\n",
    "    def __init__(self):\n",
    "        super(ColorizationUNet, self).__init__()\n",
    "        # 编码器\n",
    "        self.enc1 = ConvBlock(1, 128)         # 输入为1通道灰度图像\n",
    "        self.enc2 = ConvBlock(128, 128)\n",
    "        self.enc3 = ConvBlock(128, 256)\n",
    "        self.enc4 = ConvBlock(256, 512)\n",
    "        self.enc5 = ConvBlock(512, 512)\n",
    "        # 解码器\n",
    "        self.dec1 = UpConvBlock(512, 512)\n",
    "        self.dec2 = UpConvBlock(512 + 512, 256)  # 跳跃连接，通道数加倍\n",
    "        self.dec3 = UpConvBlock(256 + 256, 128)\n",
    "        self.dec4 = UpConvBlock(128 + 128, 128)\n",
    "        self.dec5 = UpConvBlock(128 + 128, 3)    # 输出3通道彩色图像\n",
    "        # 最后的深度可分离卷积层\n",
    "        self.final_conv = SeparableConv2d(3 + 1, 3)\n",
    "        # 激活函数\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        # 编码器路径\n",
    "        enc1 = self.enc1(x)    # 输出尺寸：(batch_size, 128, 80, 80)\n",
    "        enc2 = self.enc2(enc1) # 输出尺寸：(batch_size, 128, 40, 40)\n",
    "        enc3 = self.enc3(enc2) # 输出尺寸：(batch_size, 256, 20, 20)\n",
    "        enc4 = self.enc4(enc3) # 输出尺寸：(batch_size, 512, 10, 10)\n",
    "        enc5 = self.enc5(enc4) # 输出尺寸：(batch_size, 512, 5, 5)\n",
    "        # 解码器路径\n",
    "        dec1 = self.dec1(enc5)                      # 输出尺寸：(batch_size, 512, 10, 10)\n",
    "        dec1 = torch.cat((dec1, enc4), dim=1)       # 跳跃连接，通道数为1024\n",
    "        dec2 = self.dec2(dec1)                      # 输出尺寸：(batch_size, 256, 20, 20)\n",
    "        dec2 = torch.cat((dec2, enc3), dim=1)       # 通道数为512\n",
    "        dec3 = self.dec3(dec2)                      # 输出尺寸：(batch_size, 128, 40, 40)\n",
    "        dec3 = torch.cat((dec3, enc2), dim=1)       # 通道数为256\n",
    "        dec4 = self.dec4(dec3)                      # 输出尺寸：(batch_size, 128, 80, 80)\n",
    "        dec4 = torch.cat((dec4, enc1), dim=1)       # 通道数为256\n",
    "        dec5 = self.dec5(dec4)                      # 输出尺寸：(batch_size, 3, 160, 160)\n",
    "        # 拼接输入和解码器输出\n",
    "        dec5 = torch.cat((dec5, x), dim=1)          # 通道数为4\n",
    "        # 最后的卷积层\n",
    "        out = self.final_conv(dec5)                 # 输出尺寸：(batch_size, 3, 160, 160)\n",
    "        out = self.sigmoid(out)                     # 将输出限制在0到1之间\n",
    "        return out\n",
    "\n",
    "# 示例用法\n",
    "\n",
    "model = ColorizationUNet()\n",
    "# 创建一个示例灰度图像，尺寸为(1, 1, 160, 160)\n",
    "input_image = torch.randn(1, 1, 160, 160)\n",
    "# 前向传播\n",
    "output_image = model(input_image)\n",
    "print(output_image.shape)  # 输出尺寸应为(1, 3, 160, 160)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T17:47:38.296157Z",
     "start_time": "2024-09-24T17:47:37.038505200Z"
    }
   },
   "id": "590c99911cebde4f",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_14104\\1575611949.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('./checkpoints/colorization_epoch_50.pth', map_location=device))\n"
     ]
    }
   ],
   "source": [
    "# 读取并预处理灰度图像\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 设置模型为评估模式\n",
    "model.eval()\n",
    "\n",
    "# 读取并预处理灰度图像\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 定义与训练时相同的变换\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((160, 160)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "# 将模型移动到GPU（如果可用）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load('./checkpoints/colorization_epoch_50.pth', map_location=device))\n",
    "# 加载灰度图像并预处理\n",
    "gray_image = Image.open('landscape/color/0.jpg').convert('L')\n",
    "gray_tensor = transform(gray_image).unsqueeze(0).to(device)  # 添加批次维度并移动到设备\n",
    "\n",
    "# 使用模型进行预测\n",
    "with torch.no_grad():\n",
    "    output_color = model(gray_tensor)\n",
    "\n",
    "# 将输出转换为图像并保存\n",
    "output_color = output_color.squeeze(0).cpu().numpy()  # 移除批次维度并移动到 CPU\n",
    "output_img = np.transpose(output_color, (1, 2, 0))    # 调整维度顺序为 [H, W, C]\n",
    "\n",
    "# 保存彩色图像\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imsave('colorized_image.png', output_img)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T17:47:39.412386900Z",
     "start_time": "2024-09-24T17:47:38.298666400Z"
    }
   },
   "id": "4af0a7ee6f451851",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Image data of dtype <U19 cannot be converted to float",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimshow\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcolorized_image.png\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\mambaforge\\envs\\cv_all\\lib\\site-packages\\matplotlib\\pyplot.py:3562\u001B[0m, in \u001B[0;36mimshow\u001B[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001B[0m\n\u001B[0;32m   3541\u001B[0m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(Axes\u001B[38;5;241m.\u001B[39mimshow)\n\u001B[0;32m   3542\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mimshow\u001B[39m(\n\u001B[0;32m   3543\u001B[0m     X: ArrayLike \u001B[38;5;241m|\u001B[39m PIL\u001B[38;5;241m.\u001B[39mImage\u001B[38;5;241m.\u001B[39mImage,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   3560\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   3561\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m AxesImage:\n\u001B[1;32m-> 3562\u001B[0m     __ret \u001B[38;5;241m=\u001B[39m gca()\u001B[38;5;241m.\u001B[39mimshow(\n\u001B[0;32m   3563\u001B[0m         X,\n\u001B[0;32m   3564\u001B[0m         cmap\u001B[38;5;241m=\u001B[39mcmap,\n\u001B[0;32m   3565\u001B[0m         norm\u001B[38;5;241m=\u001B[39mnorm,\n\u001B[0;32m   3566\u001B[0m         aspect\u001B[38;5;241m=\u001B[39maspect,\n\u001B[0;32m   3567\u001B[0m         interpolation\u001B[38;5;241m=\u001B[39minterpolation,\n\u001B[0;32m   3568\u001B[0m         alpha\u001B[38;5;241m=\u001B[39malpha,\n\u001B[0;32m   3569\u001B[0m         vmin\u001B[38;5;241m=\u001B[39mvmin,\n\u001B[0;32m   3570\u001B[0m         vmax\u001B[38;5;241m=\u001B[39mvmax,\n\u001B[0;32m   3571\u001B[0m         origin\u001B[38;5;241m=\u001B[39morigin,\n\u001B[0;32m   3572\u001B[0m         extent\u001B[38;5;241m=\u001B[39mextent,\n\u001B[0;32m   3573\u001B[0m         interpolation_stage\u001B[38;5;241m=\u001B[39minterpolation_stage,\n\u001B[0;32m   3574\u001B[0m         filternorm\u001B[38;5;241m=\u001B[39mfilternorm,\n\u001B[0;32m   3575\u001B[0m         filterrad\u001B[38;5;241m=\u001B[39mfilterrad,\n\u001B[0;32m   3576\u001B[0m         resample\u001B[38;5;241m=\u001B[39mresample,\n\u001B[0;32m   3577\u001B[0m         url\u001B[38;5;241m=\u001B[39murl,\n\u001B[0;32m   3578\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m: data} \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m {}),\n\u001B[0;32m   3579\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   3580\u001B[0m     )\n\u001B[0;32m   3581\u001B[0m     sci(__ret)\n\u001B[0;32m   3582\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m __ret\n",
      "File \u001B[1;32mD:\\mambaforge\\envs\\cv_all\\lib\\site-packages\\matplotlib\\__init__.py:1473\u001B[0m, in \u001B[0;36m_preprocess_data.<locals>.inner\u001B[1;34m(ax, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1470\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m   1471\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(ax, \u001B[38;5;241m*\u001B[39margs, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m   1472\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1473\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\n\u001B[0;32m   1474\u001B[0m             ax,\n\u001B[0;32m   1475\u001B[0m             \u001B[38;5;241m*\u001B[39m\u001B[38;5;28mmap\u001B[39m(sanitize_sequence, args),\n\u001B[0;32m   1476\u001B[0m             \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m{k: sanitize_sequence(v) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m kwargs\u001B[38;5;241m.\u001B[39mitems()})\n\u001B[0;32m   1478\u001B[0m     bound \u001B[38;5;241m=\u001B[39m new_sig\u001B[38;5;241m.\u001B[39mbind(ax, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1479\u001B[0m     auto_label \u001B[38;5;241m=\u001B[39m (bound\u001B[38;5;241m.\u001B[39marguments\u001B[38;5;241m.\u001B[39mget(label_namer)\n\u001B[0;32m   1480\u001B[0m                   \u001B[38;5;129;01mor\u001B[39;00m bound\u001B[38;5;241m.\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mget(label_namer))\n",
      "File \u001B[1;32mD:\\mambaforge\\envs\\cv_all\\lib\\site-packages\\matplotlib\\axes\\_axes.py:5895\u001B[0m, in \u001B[0;36mAxes.imshow\u001B[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001B[0m\n\u001B[0;32m   5892\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m aspect \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   5893\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_aspect(aspect)\n\u001B[1;32m-> 5895\u001B[0m \u001B[43mim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   5896\u001B[0m im\u001B[38;5;241m.\u001B[39mset_alpha(alpha)\n\u001B[0;32m   5897\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m im\u001B[38;5;241m.\u001B[39mget_clip_path() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   5898\u001B[0m     \u001B[38;5;66;03m# image does not already have clipping set, clip to Axes patch\u001B[39;00m\n",
      "File \u001B[1;32mD:\\mambaforge\\envs\\cv_all\\lib\\site-packages\\matplotlib\\image.py:729\u001B[0m, in \u001B[0;36m_ImageBase.set_data\u001B[1;34m(self, A)\u001B[0m\n\u001B[0;32m    727\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(A, PIL\u001B[38;5;241m.\u001B[39mImage\u001B[38;5;241m.\u001B[39mImage):\n\u001B[0;32m    728\u001B[0m     A \u001B[38;5;241m=\u001B[39m pil_to_array(A)  \u001B[38;5;66;03m# Needed e.g. to apply png palette.\u001B[39;00m\n\u001B[1;32m--> 729\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_normalize_image_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mA\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    730\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_imcache \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    731\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstale \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32mD:\\mambaforge\\envs\\cv_all\\lib\\site-packages\\matplotlib\\image.py:692\u001B[0m, in \u001B[0;36m_ImageBase._normalize_image_array\u001B[1;34m(A)\u001B[0m\n\u001B[0;32m    690\u001B[0m A \u001B[38;5;241m=\u001B[39m cbook\u001B[38;5;241m.\u001B[39msafe_masked_invalid(A, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    691\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m A\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m!=\u001B[39m np\u001B[38;5;241m.\u001B[39muint8 \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39mcan_cast(A\u001B[38;5;241m.\u001B[39mdtype, \u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msame_kind\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 692\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mImage data of dtype \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mA\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m cannot be \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    693\u001B[0m                     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconverted to float\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    694\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m A\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m3\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m A\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    695\u001B[0m     A \u001B[38;5;241m=\u001B[39m A\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)  \u001B[38;5;66;03m# If just (M, N, 1), assume scalar and apply colormap.\u001B[39;00m\n",
      "\u001B[1;31mTypeError\u001B[0m: Image data of dtype <U19 cannot be converted to float"
     ]
    }
   ],
   "source": [
    "plt.imshow('colorized_image.png')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-09-24T17:48:07.941559300Z"
    }
   },
   "id": "cbe23527aab48754"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
